{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annihilator0/Twitter-Sentiment-Analysis-using-ML/blob/main/Twitter%20Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaggle library\n",
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "Cnk9bQTdGaRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of kaggle.jason file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "sC1cKFYPI89n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing twitter sentiment dataset"
      ],
      "metadata": {
        "id": "rqlJ2qK7JueD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#API to fetch the dataset from kaggle\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "id": "jzI0aJ2mJ0pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting compressed dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment140.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "f8aLx7r9L7oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "KzqB4WXhMw6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mqu_3hxLMrJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "xfEzvjrMPNcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the stopwords in english\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Q6OyrS5bPhjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Processing"
      ],
      "metadata": {
        "id": "V94eoUsTTUeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data from csv file to pandas dataframe\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "JU2Loq-gQFmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "nJFmLeWXU_QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printinfg the first 5 rows of the dataframe\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "W81ElfDDVTnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naming the columns and reading the datasets again\n",
        "\n",
        "column_names = ['target' , 'id' , 'date' , 'flag' , 'user' , 'text']\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', names=column_names, encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "9JfWZbq27Eno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of rows and columns again\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "OmTbpAh28Vgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printinfg the first 5 rows of the dataframe again\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "RbSgKR258hyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the number of missing values in the dataset\n",
        "twitter_data.isnull().sum()"
      ],
      "metadata": {
        "id": "bEvycAC28yFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of target column(how many positives and negatives)\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "lCrcCkSr-HFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the target \"4\" to \"1\""
      ],
      "metadata": {
        "id": "L3Sycj19-_xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.replace({'target' :{4:1}}, inplace=True)"
      ],
      "metadata": {
        "id": "wZIxCnld-sOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of target column(how many positives and negatives) again\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "3PaYKfsTAMRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0--> Negative Tweet\n",
        "\n",
        "1--> Positive Tweet"
      ],
      "metadata": {
        "id": "8cwHgUXpAqpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming** -the process of reducing a word to its root word"
      ],
      "metadata": {
        "id": "cxe8s2BqBSck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "metadata": {
        "id": "l0muIb09Aixr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ', content)#remove anything that is not an alphabet\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "\n",
        "  return stemmed_content\n",
        "  #remove special characters>tolower>split into words>stem if not present in the stopwords>join"
      ],
      "metadata": {
        "id": "Mw79V5PiEEjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)#50 min to complete\n",
        "#create a new column and the content of the column is the stemmed content"
      ],
      "metadata": {
        "id": "FKnnsw-3IC6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "M1PuLYgFImBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['stemmed_content'])"
      ],
      "metadata": {
        "id": "rqARJVNTaO7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['target'])"
      ],
      "metadata": {
        "id": "pgvnBTiVaoZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and the label\n",
        "X = twitter_data['stemmed_content'].values\n",
        "Y = twitter_data['target'].values"
      ],
      "metadata": {
        "id": "vI-iW4bRbLti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "4tIb4wvAbs2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "De5b5aT0bwON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splittin the data to training data and test data"
      ],
      "metadata": {
        "id": "ywZ1t9zrb5JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)\n",
        "# 0.2 means 20% goes to test data and rest to  training data satisfy=y means to split values equally or balance positives and negatives"
      ],
      "metadata": {
        "id": "EKoyUf2Pb1Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "790MR2pIdL6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "-GGg6tWauxsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "xXuNC38R5Uxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Textual data to numerical data"
      ],
      "metadata": {
        "id": "soViqzzN5iUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "r-JVu9PV5eaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "WoFZ3Paf60FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "ZsMEBAb27Buu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Machine Learning Model(Logistic Reggression Model)"
      ],
      "metadata": {
        "id": "iG_h74yr7V15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)#maximeme iteration until best accuracy\n"
      ],
      "metadata": {
        "id": "Mf4XLH5t7Eq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "xzll34x874Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "TcPkdIlF8ebg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "UbdPKfSy8rNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
      ],
      "metadata": {
        "id": "EHxKtnSf8KwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score of the training data : ', training_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaqVj0Ou-M6C",
        "outputId": "8b215b83-0f5b-44fd-ff8a-16f00ae085ae"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the training data :  0.79871953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "metadata": {
        "id": "xKs9wEv_-nXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score of the test data : ', test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r09a_K_4_N0A",
        "outputId": "fc8b3ada-2eb9-442b-e44f-a555f1ab52eb"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the test data :  0.77668125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model accuracy = 77.66%"
      ],
      "metadata": {
        "id": "QX5rJMYs_pUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained model"
      ],
      "metadata": {
        "id": "By9T0w-3ABWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "6vTGDkyH_Qyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "qioQSVmkAHWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the saved model for future predictions"
      ],
      "metadata": {
        "id": "9iKsV9v6An-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "nKNM6EWaAhpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[200]\n",
        "print(Y_test[200])\n",
        "\n",
        "prediction = loaded_model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print('The news is Negative')\n",
        "else:\n",
        "  print('The news is Positive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AQFmQRJA6pn",
        "outputId": "bf8558c0-dac5-478c-b6b4-6c03370ffdec"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[1]\n",
            "The news is Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[131]\n",
        "print(Y_test[131])\n",
        "\n",
        "prediction = loaded_model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print('The news is Negative')\n",
        "else:\n",
        "  print('The news is Positive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDB60SxTBRID",
        "outputId": "d80c9e6e-f490-421a-f023-9898d36971e4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[1]\n",
            "The news is Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOE-NGfWCBiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}